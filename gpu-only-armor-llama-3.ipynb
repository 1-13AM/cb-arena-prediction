{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:21:59.696252Z","iopub.status.busy":"2024-07-19T17:21:59.695970Z","iopub.status.idle":"2024-07-19T17:21:59.704542Z","shell.execute_reply":"2024-07-19T17:21:59.703961Z","shell.execute_reply.started":"2024-07-19T17:21:59.696223Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","import random\n","\n","def set_seed(seed):\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n","#     torch.backends.cudnn.deterministic = True  # Ensure deterministic behavior\n","#     torch.backends.cudnn.benchmark = False  # Ensure reproducibility, might slow down performance\n","    random.seed(seed)\n","\n","# Set the seed for all libraries\n","set_seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:21:59.705578Z","iopub.status.busy":"2024-07-19T17:21:59.705362Z","iopub.status.idle":"2024-07-19T17:21:59.734928Z","shell.execute_reply":"2024-07-19T17:21:59.734339Z","shell.execute_reply.started":"2024-07-19T17:21:59.705554Z"},"trusted":true},"outputs":[],"source":["import shutil\n","src_paths = [r\"/kaggle/input/armorm-llama3-8b-v0-1-mdl-custom/modeling_custom.py\", r\"/kaggle/input/lmsys-ddp-for-armor-llama/lmsys_ddp.py\"]\n","dst_path = r\"/kaggle/working/\"\n","for src_path in src_paths:\n","    shutil.copy(src_path, dst_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-19T17:21:59.736835Z","iopub.status.busy":"2024-07-19T17:21:59.736547Z","iopub.status.idle":"2024-07-19T17:21:59.740168Z","shell.execute_reply":"2024-07-19T17:21:59.739519Z","shell.execute_reply.started":"2024-07-19T17:21:59.736810Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import ast\n","import re\n","from typing import List"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:21:59.741181Z","iopub.status.busy":"2024-07-19T17:21:59.740948Z","iopub.status.idle":"2024-07-19T17:21:59.751629Z","shell.execute_reply":"2024-07-19T17:21:59.751063Z","shell.execute_reply.started":"2024-07-19T17:21:59.741158Z"},"trusted":true},"outputs":[],"source":["INPUT_SIZE = 19\n","HIDDEN_SIZE = 128\n","NUM_CLASSES = 3\n","BATCH_SIZE = 8\n","PER_DEVICE_TRAIN_BATCH_SIZE = PER_DEVICE_EVAL_BATCH_SIZE = 1\n","NUM_EPOCH = 1\n","GRADIENT_ACCUMULATION_STEPS = 8\n","MODEL_CKPT = \"RLHFlow/ArmoRM-Llama3-8B-v0.1\"\n","LEARNING_RATE = 1e-4\n","MAX_LENGTH = 1536\n","# Might take a look at LoRA to remind myself of how these hyperparameters work\n","LORA_R = 4\n","LORA_ALPHA = LORA_R * 2\n","LORA_DROPOUT = 0.05\n","LORA_BIAS = 'none'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:21:59.752580Z","iopub.status.busy":"2024-07-19T17:21:59.752374Z","iopub.status.idle":"2024-07-19T17:22:08.907196Z","shell.execute_reply":"2024-07-19T17:22:08.906440Z","shell.execute_reply.started":"2024-07-19T17:21:59.752558Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_pickle('/kaggle/input/lmsys-preprocessed-data/preprocessed_data.pkl')\n","def truncate(df, max_length):\n","    def truncation_op(x, col: str, max_len: int = 1024):\n","        return x[col][:min(len(x[col]), max_len)]\n","    \n","    df['input_ids_a'] = df.apply(truncation_op, args=('input_ids_a', max_length), axis=1)\n","    df['input_ids_b'] = df.apply(truncation_op, args=('input_ids_b', max_length), axis=1)\n","    \n","    return df\n","\n","train_df = truncate(train_df, MAX_LENGTH)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:22:08.908586Z","iopub.status.busy":"2024-07-19T17:22:08.908323Z","iopub.status.idle":"2024-07-19T17:22:08.913081Z","shell.execute_reply":"2024-07-19T17:22:08.912468Z","shell.execute_reply.started":"2024-07-19T17:22:08.908560Z"},"trusted":true},"outputs":[],"source":["token_pattern = [128009, 128006, 78191, 128007, 271]\n","def find_token_for_gating(lst, ):\n","    \"\"\"Find the last occurrence of a token_pattern in a list.\"\"\"\n","    token_pattern_len = len(token_pattern)\n","    search_end = len(lst)\n","    for j in range(search_end - token_pattern_len, -1, -1):\n","        if lst[j:j + token_pattern_len] == token_pattern:\n","            return j\n","    return -1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:22:08.914150Z","iopub.status.busy":"2024-07-19T17:22:08.913897Z","iopub.status.idle":"2024-07-19T17:22:14.395388Z","shell.execute_reply":"2024-07-19T17:22:14.394634Z","shell.execute_reply.started":"2024-07-19T17:22:08.914126Z"},"trusted":true},"outputs":[],"source":["# remove all data points where the prompt token lengths exceed \n","exp = []\n","for i in range(len(train_df)): \n","    if(find_token_for_gating(train_df.iloc[i]['input_ids_a']) < 0):\n","        exp.append(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:22:14.396764Z","iopub.status.busy":"2024-07-19T17:22:14.396509Z","iopub.status.idle":"2024-07-19T17:22:14.420896Z","shell.execute_reply":"2024-07-19T17:22:14.420116Z","shell.execute_reply.started":"2024-07-19T17:22:14.396738Z"},"trusted":true},"outputs":[],"source":["# remove these rows from training data        \n","train_df = train_df.drop(index=exp)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:22:14.423521Z","iopub.status.busy":"2024-07-19T17:22:14.423269Z","iopub.status.idle":"2024-07-19T17:22:15.876560Z","shell.execute_reply":"2024-07-19T17:22:15.875523Z","shell.execute_reply.started":"2024-07-19T17:22:14.423497Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForSequenceClassification\n","from functools import partial\n","import torch\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_CKPT)"]},{"cell_type":"markdown","metadata":{},"source":["### Prepare datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:22:15.878117Z","iopub.status.busy":"2024-07-19T17:22:15.877797Z","iopub.status.idle":"2024-07-19T17:22:21.374369Z","shell.execute_reply":"2024-07-19T17:22:21.373265Z","shell.execute_reply.started":"2024-07-19T17:22:15.878086Z"},"trusted":true},"outputs":[],"source":["from datasets import Dataset, DatasetDict\n","train_df_cop = train_df.copy()\n","dataset = Dataset.from_pandas(train_df_cop[['input_ids_a', 'input_ids_b', 'label']])\n","dataset.set_format(type=\"torch\")\n","shuffled_dataset = dataset.shuffle(seed=42)\n","train_test_split = shuffled_dataset.train_test_split(test_size=0.2)\n","\n","# Optionally, you can wrap them in a DatasetDict for easier handling\n","dataset_dict = DatasetDict({\n","    'train': train_test_split['train'],\n","    'validation': train_test_split['test']\n","})"]},{"cell_type":"markdown","metadata":{},"source":["# Build a network for model comparison"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:22:21.376578Z","iopub.status.busy":"2024-07-19T17:22:21.375780Z","iopub.status.idle":"2024-07-19T17:22:21.399249Z","shell.execute_reply":"2024-07-19T17:22:21.398421Z","shell.execute_reply.started":"2024-07-19T17:22:21.376537Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from modeling_custom import LlamaForRewardModelWithGating\n","\n","class SwiGLU(nn.Module):\n","    def forward(self, x):\n","        x, gate = x.chunk(2, dim=-1)\n","        return F.silu(gate) * x\n","\n","class DualInputInteractionNetwork(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(DualInputInteractionNetwork, self).__init__()\n","        self.classification_head = nn.Sequential(nn.Linear(input_size, hidden_size),\n","                                                 nn.Linear(hidden_size, hidden_size),\n","                                                 nn.Linear(hidden_size, num_classes)  # Combining interaction features\n","                                                )\n","\n","    def forward_one(self, x):\n","        x = F.silu(self.shared_fc1(x))\n","        x = F.silu(self.shared_fc2(x))\n","        return x\n","    \n","    @staticmethod\n","    def SwiGLU(x):\n","        x, gate = x.chunk(2, dim=-1)\n","        return F.silu(gate) * x\n","    \n","    def forward(self, inputs: dict, reward_transform_matrix: torch.Tensor):\n","        \n","        batch_size = inputs.rewards.shape[0]\n","        model_a_idx = torch.arange(0, batch_size, 2)\n","        model_b_idx = model_a_idx + 1\n","        \n","        multi_obj_rewards_a = inputs.rewards[model_a_idx]\n","        multi_obj_rewards_b = inputs.rewards[model_b_idx]\n","        \n","        multi_obj_coeffs_a = inputs.gating_output[model_a_idx] @ reward_transform_matrix.T\n","        multi_obj_coeffs_b = inputs.gating_output[model_b_idx] @ reward_transform_matrix.T\n","        \n","        scaled_mul_obj_rewards_a = multi_obj_rewards_a * multi_obj_coeffs_a\n","        scaled_mul_obj_rewards_b = multi_obj_rewards_b * multi_obj_coeffs_b\n","        \n","        output = self.classification_head(scaled_mul_obj_rewards_a - scaled_mul_obj_rewards_b)\n","        \n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:22:53.162494Z","iopub.status.busy":"2024-07-19T17:22:53.162076Z","iopub.status.idle":"2024-07-19T17:22:53.171780Z","shell.execute_reply":"2024-07-19T17:22:53.170995Z","shell.execute_reply.started":"2024-07-19T17:22:53.162458Z"},"trusted":true},"outputs":[],"source":["from typing import Optional\n","\n","class LLaMaPreferencePredictionModel(nn.Module):\n","    \n","    def __init__(self, reward_model_ckpt, reward_model_quant_config: BitsAndBytesConfig, \n","                 lora_config: Optional[dict] = None, \n","                 **dual_input_interaction_kwargs):\n","        \"\"\"\n","        there are Gemma variants for ArMor\n","        \"\"\"\n","        \n","        super().__init__()\n","        self.reward_model = LlamaForRewardModelWithGating.from_pretrained(reward_model_ckpt, \n","                                                                          quantization_config=reward_model_quant_config\n","                                                                                            )\n","        \n","        self.preference_prediction_model = DualInputInteractionNetwork(**dual_input_interaction_kwargs)\n","        \n","        self.register_buffer('reward_transform_matrix', self.reward_model.reward_transform_matrix)\n","        \n","        if lora_config is not None:\n","            self.lora_setup(**lora_config)\n","            \n","    def lora_config(self, **lora_config):\n","        \n","        from peft import LoraConfig, TaskType\n","        self.lora_config = LoraConfig(**lora_config,\n","                                target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n","                                task_type=TaskType.SEQ_CLS)\n","        \n","    def lora_setup(self, **lora_config):\n","        \n","        from peft import get_peft_model, prepare_model_for_kbit_training\n","        self.lora_config(**lora_config)\n","        \n","        self.reward_model = prepare_model_for_kbit_training(self.reward_model)\n","        self.reward_model = get_peft_model(self.reward_model, self.lora_config)\n","    \n","        \n","    def forward(self, input_ids, attention_mask, label=None):\n","        # there are data fields that the ArMor model does not require, so passing kwargs would be the temporary solution\n","        # armoRM framework only takes input_ids as inputs\n","        \n","        reward_model_output = self.reward_model(input_ids, attention_mask)\n","        logits = self.preference_prediction_model(reward_model_output, self.reward_transform_matrix)\n","        if label is None:\n","            return {\"reward_model_output\": reward_model_output,\n","                    \"logits\": logits}\n","        \n","        return {\"reward_model_output\": reward_model_output,\n","                \"logits\": logits,\n","                \"label\": label}"]},{"cell_type":"markdown","metadata":{},"source":["### Create a custom data collator & trainer for this use case"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:22:54.991231Z","iopub.status.busy":"2024-07-19T17:22:54.990837Z","iopub.status.idle":"2024-07-19T17:22:55.002921Z","shell.execute_reply":"2024-07-19T17:22:55.002169Z","shell.execute_reply.started":"2024-07-19T17:22:54.991186Z"},"trusted":true},"outputs":[],"source":["from transformers import Trainer\n","from transformers import DataCollatorWithPadding\n","from dataclasses import dataclass\n","from typing import Union, Dict, Any\n","from transformers.tokenization_utils_base import PaddingStrategy\n","\n","@dataclass\n","class RewardDataCollatorWithPadding:\n","    tokenizer: AutoTokenizer\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    return_tensors: str = \"pt\"\n","\n","    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n","        merged_features = []\n","        for feature in features:\n","            merged_features.append(\n","                {\n","                    \"input_ids\": feature[\"input_ids_a\"]\n","                }\n","            )\n","            merged_features.append(\n","                {\n","                    \"input_ids\": feature[\"input_ids_b\"]\n","                }\n","            )\n","        batch = self.tokenizer.pad(\n","            merged_features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=self.return_tensors,\n","        )\n","        batch = {\n","            \"input_ids\": batch[\"input_ids\"],\n","            \"attention_mask\": batch[\"attention_mask\"],\n","            \"label\": torch.tensor([feature[\"label\"].item() for feature in features])\n","        }\n","        \n","        return batch\n","                    \n","class RewardTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        outputs = model(\n","            input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], label=inputs['label']\n","        )\n","        logits, targets = outputs['logits'], outputs['label']\n","        loss = nn.functional.cross_entropy(logits, targets).mean()\n","        \n","        return loss\n","\n","def compute_metrics(pred):\n","    \n","    # Get the predictions and labels from the pred argument\n","    logits, labels = pred\n","    predictions = np.argmax(logits, axis=-1)\n","    \n","    # Calculate cross entropy loss\n","    # Convert logits to PyTorch tensor\n","    logits_tensor = torch.tensor(logits)\n","    labels_tensor = torch.tensor(labels)\n","    \n","    # Compute cross entropy loss\n","    cross_entropy_loss = F.cross_entropy(logits_tensor, labels_tensor).item()\n","\n","    return {\n","        \"cross_entropy_loss\": cross_entropy_loss\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:23:00.916025Z","iopub.status.busy":"2024-07-19T17:23:00.915306Z","iopub.status.idle":"2024-07-19T17:23:00.920724Z","shell.execute_reply":"2024-07-19T17:23:00.919990Z","shell.execute_reply.started":"2024-07-19T17:23:00.915985Z"},"trusted":true},"outputs":[],"source":["# from transformers import BitsAndBytesConfig, AutoModelForSequenceClassification, AutoTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","from modeling_custom import LlamaForRewardModelWithGating\n","import torch\n","\n","nf4_config = BitsAndBytesConfig(\n","   load_in_4bit=True,\n","   bnb_4bit_quant_type=\"nf4\",\n","   bnb_4bit_use_double_quant=True, # quantize the quantization factor, which saves another 0.4 bit/parameter\n","   bnb_4bit_compute_dtype=torch.float16 # configure computations to be in (b)float16\n",")\n","\n","lora_config = {'r': LORA_R,\n","               'lora_alpha': LORA_ALPHA,\n","               'lora_dropout': LORA_DROPOUT,\n","               'bias': LORA_BIAS\n","                }"]},{"cell_type":"markdown","metadata":{},"source":["### Multi-GPU training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:23:13.535171Z","iopub.status.busy":"2024-07-19T17:23:13.534426Z","iopub.status.idle":"2024-07-19T17:23:13.557269Z","shell.execute_reply":"2024-07-19T17:23:13.556410Z","shell.execute_reply.started":"2024-07-19T17:23:13.535125Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader, TensorDataset, DistributedSampler\n","from tqdm import tqdm\n","from accelerate import Accelerator\n","from torch.optim import AdamW\n","from transformers import get_scheduler\n","\n","def create_dataloaders(dataset_dict: DatasetDict, data_collator, batch_size: int = 4):\n","    train_dataloader = DataLoader(dataset_dict['train'], batch_size=batch_size, collate_fn=data_collator)\n","    eval_dataloader = DataLoader(dataset_dict['validation'], batch_size=batch_size, collate_fn=data_collator)\n","    return train_dataloader, eval_dataloader\n","\n","def train_one_epoch(model, dataloader, optimizer, criterion, accelerator, lr_scheduler, epoch):\n","    accelerator.print(\"Training on one epoch\")\n","    model.train()\n","    epoch_loss, step_loss = 0., 0.\n","    for i, batch in enumerate(tqdm(dataloader, desc=f'Epoch {epoch+1}')):\n","#         print(batch['input_ids'].shape)\n","        with accelerator.accumulate(model):\n","            # Forward pass\n","            outputs = model(\n","                input_ids=batch['input_ids'],\n","                attention_mask=batch[\"attention_mask\"], \n","                label=batch['label']\n","            )\n","            \n","            logits = outputs['logits']\n","            loss = criterion(logits, batch['label'])\n","            step_loss += loss.item()\n","            epoch_loss += loss.item()\n","            \n","            if (i + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n","                accelerator.log({\"train_loss\": step_loss / GRADIENT_ACCUMULATION_STEPS, \"epoch\": epoch + 1})\n","                step_loss = 0.\n","                \n","            accelerator.backward(loss)\n","            optimizer.step()\n","            lr_scheduler.step()\n","            optimizer.zero_grad()\n","\n","    accelerator.print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}\")\n","    \n","def eval_one_epoch(model, dataloader, optimizer, criterion, accelerator, lr_scheduler, epoch):\n","    model.eval()\n","    epoch_loss = 0\n","    \n","    for batch in tqdm(dataloader):\n","\n","        # Forward pass\n","        outputs = model(\n","                input_ids=batch['input_ids'],\n","                attention_mask=batch[\"attention_mask\"], \n","                label=batch['label']\n","            )\n","        \n","        logits = outputs['logits']\n","        loss = criterion(logits, batch['label'])\n","        epoch_loss += loss.item()\n","    \n","    accelerator.log({\"epoch_loss\": epoch_loss / len(dataloader), \"epoch\": epoch + 1})\n","    \n","    accelerator.print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}\")\n","    \n","\n","def main_train_loop(model, dataset_dict, data_collator, mixed_precision, batch_size, gradient_accumulation_steps, num_epoch, learning_rate):\n","    \n","    !pip install peft -U -qq\n","    accelerator = Accelerator(mixed_precision=mixed_precision, \n","                              gradient_accumulation_steps=gradient_accumulation_steps,\n","                              log_with=\"wandb\"\n","                             )\n","    \n","    model = LLaMaPreferencePredictionModel(reward_model_ckpt=MODEL_CKPT, \n","                                       reward_model_quant_config=nf4_config, \n","                                       lora_config=lora_config,\n","                                       input_size=INPUT_SIZE, \n","                                       hidden_size=HIDDEN_SIZE, \n","                                       num_classes=NUM_CLASSES) \n","    \n","    if accelerator.is_local_main_process:\n","        accelerator.init_trackers(\n","        project_name=\"distributed_training\",\n","        init_kwargs={\"wandb\": {\"entity\": \"ashton_h\", \"name\": \"armor-1-epoch\"}}\n","        )\n","    \n","    train_dataloader, eval_dataloader = create_dataloaders(dataset_dict, data_collator, batch_size)\n","    \n","    def print_trainable_parameters(model):\n","        \"\"\"\n","        Prints the number of trainable parameters in the model.\n","        \"\"\"\n","        trainable_params = 0\n","        all_param = 0\n","        for _, param in model.named_parameters():\n","            all_param += param.numel()\n","            if param.requires_grad:\n","                trainable_params += param.numel()\n","        accelerator.print(\n","            f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","        )\n","        \n","    # print the number of trainable parameters\n","    print_trainable_parameters(model)\n","\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    criterion = nn.CrossEntropyLoss()\n","    lr_scheduler = get_scheduler(\n","        \"cosine\", optimizer=optimizer, num_warmup_steps=0.03, num_training_steps=len(train_dataloader) * num_epoch\n","    )\n","    \n","    model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(model, optimizer, train_dataloader, eval_dataloader, lr_scheduler)\n","    \n","    for epoch in range(num_epoch):\n","        train_one_epoch(model, train_dataloader, optimizer, criterion, accelerator, lr_scheduler, epoch)\n","        try:\n","            eval_one_epoch(model, eval_dataloader, optimizer, criterion, accelerator, lr_scheduler, epoch)\n","        except Exception as e:\n","            print(e)\n","            pass\n","        \n","    if accelerator.is_local_main_process:\n","        accelerator.end_training()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:23:17.438419Z","iopub.status.busy":"2024-07-19T17:23:17.437663Z","iopub.status.idle":"2024-07-19T17:23:17.442496Z","shell.execute_reply":"2024-07-19T17:23:17.441735Z","shell.execute_reply.started":"2024-07-19T17:23:17.438377Z"},"trusted":true},"outputs":[],"source":["data_collator = RewardDataCollatorWithPadding(tokenizer, padding='longest')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:25:12.935789Z","iopub.status.busy":"2024-07-19T17:25:12.935450Z","iopub.status.idle":"2024-07-19T17:25:48.334935Z","shell.execute_reply":"2024-07-19T17:25:48.334215Z","shell.execute_reply.started":"2024-07-19T17:25:12.935759Z"},"trusted":true},"outputs":[],"source":["import wandb\n","wandb.init()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T17:25:53.591798Z","iopub.status.busy":"2024-07-19T17:25:53.591364Z","iopub.status.idle":"2024-07-19T17:26:05.814375Z","shell.execute_reply":"2024-07-19T17:26:05.813103Z","shell.execute_reply.started":"2024-07-19T17:25:53.591749Z"},"trusted":true},"outputs":[],"source":["from accelerate import notebook_launcher\n","args = (dataset_dict, data_collator, \"bf16\", BATCH_SIZE, GRADIENT_ACCUMULATION_STEPS, NUM_EPOCH, LEARNING_RATE)\n","notebook_launcher(main_train_loop, args, num_processes=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8346466,"sourceId":66631,"sourceType":"competition"},{"datasetId":5350506,"sourceId":8900034,"sourceType":"datasetVersion"},{"datasetId":5361778,"sourceId":8915911,"sourceType":"datasetVersion"},{"datasetId":5381992,"isSourceIdPinned":true,"sourceId":8944605,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
